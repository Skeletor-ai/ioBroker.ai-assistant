{
  "tabGeneral": "Allgemein",
  "tabLlm": "LLM Backend",
  "tabTemplates": "Vorlagen",

  "headerGeneral": "Allgemeine Einstellungen",
  "audioPort": "Audio-Server Port",
  "audioPortHelp": "HTTP-Port für den Audio-Empfang (ESP32, Browser etc.)",
  "whisperModel": "Whisper Modell",
  "whisperModelHelp": "Größe des Whisper-Modells. Größere Modelle sind genauer, brauchen aber mehr RAM und Zeit.",
  "whisperLanguage": "Sprache",
  "whisperLanguageHelp": "ISO-Sprachcode für die Spracherkennung (z.B. de, en, fr)",

  "headerTts": "Text-to-Speech (TTS)",
  "ttsEnabled": "TTS aktivieren",
  "ttsEnabledHelp": "Antworten als Sprache zurückgeben (für ESP32 oder Browser-Wiedergabe)",
  "ttsBackend": "TTS Backend",
  "ttsBackendHelp": "Piper läuft lokal, Edge-TTS nutzt Microsofts kostenlosen Online-Dienst",
  "piperModel": "Piper Modell",
  "piperModelHelp": "Name des Piper-Modells (z.B. de_DE-thorsten-high)",
  "edgeTtsVoice": "Edge-TTS Stimme",
  "edgeTtsVoiceHelp": "Name der Edge-TTS Stimme (z.B. de-DE-ConradNeural)",

  "testWhisper": "Whisper testen",

  "headerLlm": "LLM Backend Konfiguration",
  "llmBackend": "LLM Backend",
  "llmBackendHelp": "Welches KI-Backend für die Sprachverarbeitung verwenden",
  "ollamaUrl": "Ollama URL",
  "ollamaUrlHelp": "URL des lokalen Ollama-Servers",
  "ollamaModel": "Ollama Modell",
  "ollamaModelHelp": "Name des Ollama-Modells (z.B. phi3:mini, llama3, mistral)",
  "openaiApiKey": "OpenAI API-Key",
  "openaiApiKeyHelp": "Ihr OpenAI API-Schlüssel (beginnt mit sk-...)",
  "openaiModel": "OpenAI Modell",
  "openaiModelHelp": "Name des OpenAI-Modells (z.B. gpt-4o-mini, gpt-4o)",
  "anthropicApiKey": "Anthropic API-Key",
  "anthropicApiKeyHelp": "Ihr Anthropic API-Schlüssel (beginnt mit sk-ant-...)",
  "anthropicModel": "Anthropic Modell",
  "anthropicModelHelp": "Name des Claude-Modells (z.B. claude-sonnet-4-20250514)",
  "maxContextTokens": "Max. Kontext-Tokens",
  "maxContextTokensHelp": "Maximale Anzahl an Tokens für den Kontext (System-Prompt + ioBroker-Zustände)",
  "testLlm": "LLM-Verbindung testen",

  "headerTemplates": "Vorlagen-Konfiguration",
  "templateInfo": "Vorlagen definieren, wie der Assistent auf bestimmte Spracheingaben reagiert. Jede Vorlage hat Trigger-Wörter, einen System-Prompt und erlaubte Aktionen. Kontext-Quellen und erlaubte Aktionen werden als kommagetrennte ioBroker-Zustandsmuster angegeben (z.B. 'hm-rpc.0.*.TEMPERATURE' für alle Temperatursensoren).",
  "templates": "Vorlagen",
  "templateId": "ID",
  "templateName": "Name",
  "templateTriggerWords": "Trigger-Wörter (kommagetrennt)",
  "templateSystemPrompt": "System-Prompt",
  "templateResponseFormat": "Antwortformat",
  "templateMaxContextStates": "Max. Kontext-Zustände",

  "headerAdvanced": "Hinweise zur erweiterten Konfiguration",
  "advancedInfo": "Für Kontext-Quellen (contextSources) und erlaubte Aktionen (allowedActions) können Sie in den Vorlagen-Objekten direkt im JSON-Format Unter-Tabellen mit 'pattern' und 'label' Feldern definieren. Beispiel: [{\"pattern\": \"hm-rpc.0.*.TEMPERATURE\", \"label\": \"Temperaturen\"}]. Diese erweiterten Felder können über die Datei-Konfiguration oder das JSON-Objekt bearbeitet werden."
}
